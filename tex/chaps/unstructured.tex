
In this Chapter we implement a finite element method (FEM) for an unstructured triangular mesh on a general polygonal domain in the plane.  Our code solves certain linear and nonlinear Poisson equation problems with reasonably-general boundary conditions.  The approach is to
\begin{center}
\emph{first do element-wise assembly of the residual equations,}
\end{center}
and thereby get a functioning \pSNES-based code.  No explicit matrix construction is needed in writing the initial code.  Only after making sure it works do we
\begin{center}
\emph{write additional code to assemble an approximate Jacobian matrix.}
\end{center}

We do the following new tasks in this Chapter:
\begin{itemize}
\item implement Neumann boundary conditions,
\item read a triangular mesh from a file into \PETSc \pVecs and \pISs,
\item index that mesh in an unstructured way, and
\item pre-allocate a \PETSc \pMat.
\end{itemize}

Similarly to the example in the last Chapter, the residual equations $\bF(\bu)=0$, which is to say the nonlinear system seen by the \pSNES solver, is the discretized weak form of the PDE.  Our direct construction of these equations roughly follows the residual implementations of Chapters \ref{chap:nl}--\ref{chap:of}.

The FEM ``stiffness'' matrix $A$, a major piece in typical FEM introductions \citep{Braess2007,Elmanetal2005}, arises here as the Jacobian when solving $\bF(\bu)=0$.  In our first runs the \pSNES solver approximates this linear system through finite-differencing evaluations of $\bF$.  Eventually we do assemble a Jacobian, but one that is only correct for the linear case.  For the smooth nonlinear case tested here, however, this ``Picard'' approximate linearization suffices.

The example here contrasts with the rectangular-element ($Q^1$) FEM of the last Chapter by not using a \pDMDA and a structured grid.  Instead we implement our own minimal mesh-topology infrastructure, which substantially increases our workload.  The relatively-simple \Triangle program generates the ASCII files which define input meshes.  An ``index set'' \pIS  type holds the global indices of nodes and triangles (elements).  \pVec and \pMat objects, used for the solution and Jacobian respectively, are indexed through the \pIS values.

In contrast with both earlier and later Chapters, we generate a code that only works on one MPI process (i.e.~a serial code).  However, at the end of the Chapter we briefly consider the additional constructs needed to distribute a mesh across many processes.  These considerations motivate the \pDMPlex example in Chapter \ref{chap:dp}.  The benefits of \PETSc's mesh-topology \pDM tools, including \pDMDA in previous Chapters and \pDMPlex in Chapter \ref{chap:dp}, become clearer by forgoing them here.


\section{A 2D nonlinear Poisson problem}

\begin{marginfigure}
\input{tikz/generalpoissondomain.tex}
\caption{Problem \eqref{eq:un:poissonstrong} on a domain.}
\label{fig:un:generalpoissondomain}
\end{marginfigure}

Let $\Omega \subset \RR^2$ be a bounded (open) region as in Figure \ref{fig:un:generalpoissondomain}.  We suppose its boundary $\partial\Omega$ is well-behaved, for example polygonal or Lipschitz-continuous \citep[section 1.2]{Ciarlet2002}.  Also we decompose the boundary into (measurable) disjoint subsets $\partial_D \Omega$ and $\partial_N \Omega$.

Chapter \ref{chap:st} solves the Poisson equation $- \grad^2 u = f$.  Here we allow a more general nonlinear form.  Let $a(u,x,y)$ and $f(u,x,y)$ be given and assume there is $\eps$ so that
\begin{equation}
a(u,x,y) \ge \eps > 0, \label{eq:un:uniformelliptic}
\end{equation}
that is, \emph{uniform ellipticity} \citep{Evans2010}.  Boundary conditions are also needed, and we allow nonhomogeneous Dirichlet and Neumann type.  Let $\partial u/\partial n = \bn \cdot \grad u$ where $\bn$ is the outward unit normal on $\partial \Omega$ (Figure \ref{fig:un:generalpoissondomain}).  The nonlinear Poisson \emph{strong form} we solve finds $u(x,y)$ so that
\begin{align}
- \Div \left(a(u,x,y) \grad u\right) &= f(u,x,y) \quad \text{ on } \Omega, \label{eq:un:poissonstrong} \\
u &= g_D \quad \text{ on } \partial_D \Omega, \notag \\
\frac{\partial u}{\partial n} &= g_N \quad \text{ on } \partial_N \Omega. \notag
\end{align}

The data of problem \eqref{eq:un:poissonstrong} includes a \emph{diffusion coefficient} $a$, a \emph{source term} $f$, \emph{Dirichlet data} $g_D$, and \emph{Neumann data} $g_N$.  For the purpose of numerical solutions we will assume these data are continuous.  Poisson problem \eqref{poissonsquare} in Chapter \ref{chap:st} is the homogeneous Dirichlet case where $\Omega$ is a square, $a = 1$, $f=f(x,y)$, $\partial_D \Omega = \partial \Omega$, $\partial_N \Omega = \emptyset$, and $g_D=0$.

More general boundary conditions are conceivable in \eqref{eq:un:poissonstrong}, in particular \emph{Robin} conditions $\alpha u + \beta \frac{\partial u}{\partial n} = \gamma$ where $\alpha,\beta,\gamma$ could vary along the boundary \citep{Elmanetal2005}; see Exercise \ref{chap:un}.\ref{exer:un:robin}.  One could also allow $a$ and/or $f$ to depend on the gradient of $u$; recall $a=|\grad u|^{p-2}$ in the $p$-Laplacian equation of Chapter \ref{chap:of}, for example, but our code is limited to problem \eqref{eq:un:poissonstrong}.

As \eqref{eq:un:poissonstrong} is stated there may be no solution where ``$\Div(a\grad u)$'' makes sense as a continuous function, even for polygonal regions and continuous data.  That is, there may be no $u\in C^2(\Omega) \cap C(\overline \Omega)$ so that \eqref{eq:un:poissonstrong} applies at all points.  On the other hand, at least in the linear case, a solution exists if we convert \eqref{eq:un:poissonstrong} to a weak formulation.  It already arose in Chapter \ref{chap:of} as the gradient of an objective function, but the weak form in this Chapter generally does not have a minimization origin; see Exercise \ref{chap:un}.\ref{exer:un:notminimization}.  Here we derive the weak form from the strong form simply by multiplying by a test function and integrating.


\section{Weak form with general boundary values}

Recall $L^2(\Omega)$ is the space of square-integrable real functions on $\Omega$ and that $W^{1,2}(\Omega)$ is the Sobolev space in which the gradient is also square integrable.\sidenote{See definition \eqref{eq:of:sobolevdefn}.}  We use two subsets of $W^{1,2}(\Omega)$: \emph{trial functions} $W^{1,2}_g(\Omega)$, with value $g_D$ along $\partial_D \Omega$, and \emph{test functions} $W^{1,2}_0(\Omega)$, with value $0$ along $\partial_D \Omega$.

Choose any $v\in W^{1,2}_0(\Omega)$, multiply the first equation in \eqref{eq:un:poissonstrong} by $v$, and integrate by parts:
\begin{equation*}
\int_\Omega a(u) \grad u \cdot \grad v - \int_{\partial\Omega} \frac{\partial u}{\partial n} v = \int_\Omega f(u) v.
\end{equation*}
(In writing such integrals we show dependence on the solution $u$ but suppress it for $x,y$.)  Next use the boundary information, $v=0$ on $\partial_D\Omega$ and $\partial u/\partial n=g_N$ on $\partial_N\Omega$:
\begin{equation}
\int_\Omega a(u) \grad u \cdot \grad v = \int_\Omega f(u) v + \int_{\partial_N\Omega} g_N v\quad \text{ for any } v\in W^{1,2}_0(\Omega). \label{eq:un:poissonweak}
\end{equation}

Equation \eqref{eq:un:poissonweak} is the \emph{weak formulation} of \eqref{eq:un:poissonstrong}.  Any $u \in W^{1,2}_g(\Omega)$ satisfying \eqref{eq:un:poissonweak} is a \emph{weak solution}.  Observe that the Dirichlet boundary conditions $g_D$ are incorporated into defining $W^{1,2}_g(\Omega)$ while the Neumann boundary data $g_N$ appears in \eqref{eq:un:poissonweak}.  Recall the ``rules'' for passing between the strong \eqref{eq:un:poissonstrong} and weak \eqref{eq:un:poissonweak} formulations:\begin{itemize}
\item A well-behaved function $u \in C^2(\Omega) \cap C(\overline \Omega)$ which satisfies \eqref{eq:un:poissonstrong} also solves \eqref{eq:un:poissonweak}.  The derivation above shows this.
\item If $u \in W^{1,2}_g(\Omega)$ solves \eqref{eq:un:poissonweak} then we accept it, by definition, as a solution.   If it is also well-behaved, e.g.~$u \in C^2(\Omega) \cap C(\overline \Omega)$, then we may reverse the derivation to show it solves \eqref{eq:un:poissonstrong}.
\end{itemize}

For the linear case, where functions $a$ and $f$ are independent of $u$, the theory of \eqref{eq:un:poissonweak} is relatively-complete.  In fact, if $\partial_D \Omega$ has positive measure then a solution to \eqref{eq:un:poissonweak} exists and is unique (\emph{well-posedness}; \citep{Ciarlet2002,Evans2010}).  Furthermore there exist conditions on the domain (e.g.~it is a convex polygon) and the boundary data, from which one can show that $u$ solving \eqref{eq:un:poissonweak} is in $C^2(\Omega) \cap C(\overline \Omega)$ (\emph{regularity}; \citep{Evans2010}).

In nonlinear cases each particular problem must be analyzed for well-posedness.  In terms of practical computation, however, some important nonlinear cases are covered by our method and are solvable using the code we construct in this Chapter.  These include the 2D versions of
\begin{itemize}
\item the \emph{Bratu} equation wherein $a\equiv 1$ and $f=\lambda e^u$, and
\item ``uniformized'' \emph{porous medium} equations \citep{Ockendonetal2003}, in which, for example, $a=u^{m-1}+\eps$ for some $m\ge 1$ and $\eps>0$.
\end{itemize}
For the former see Exercise \ref{chap:un}.\ref{exer:un:bratu}.\sidenote{Exercise \ref{chap:nl}.\ref{exer:nl:bratu} solves the 1D version.}  In this Chapter we test our code on an easy case of the latter, namely with $a(u)=1+u^2$.


\section{A $P^1$ finite element method}

Our FEM for the Poisson problem seeks $u$, from a finite-dimensional subspace of $W^{1,2}_g(\Omega)$, for which \eqref{eq:un:poissonweak} holds for all test functions $v$ in a finite-dimensional subspace of $W^{1,2}_0(\Omega)$.  In the \emph{Galerkin} method here, these subspaces, both built from a triangulation of $\Omega$, are essentially the same.

First, assume $\Omega$ is polygonal so that $\partial\Omega$ is a closed polygon (Figure \ref{fig:un:polygon}).  We also require that the segments forming $\partial\Omega$ are either entirely in $\partial_D\Omega$ or entirely in $\partial_N\Omega$ and that $\partial_D\Omega$ is closed and contains at least one segment of positive length.  (This leads to well-posedness of the continuum problem, at least in the linear case.)

\begin{marginfigure}
\input{tmp/blob.tikz}
\caption{A polygonal domain $\Omega$.  The Dirichlet portion of the boundary $\partial_D\Omega$ is shown in bold.}
\label{fig:un:polygon}
\end{marginfigure}

By definition, a \emph{triangulation} is a finite set of non-overlapping, non-empty open triangles $\triangle_k$ which tile $\Omega$:
\begin{equation}
\Th = \left\{\triangle_k \,\Big|\, \cup_k \overline{\triangle}_k = \overline{\Omega} \, \text{ and} \,\, \triangle_k \cap \triangle_l = \emptyset \, \text{ if } k\ne l\right\}. \label{eq:un:triangulation}
\end{equation}
An example triangulation $\Th$ is shown in Figure \ref{fig:un:number-mesh}.  The subscript ``$h$'' in notation ``$\Th$'' denotes the typical or maximum size $h$ (e.g.~maximum side length) of the triangles.  It is also a reminder of our desired limit $h\to 0$.

In contrast to many references, such as \citet{Elmanetal2005}, which we follow in many other ways, numbering here is zero-based, suitable for a C implementation.  Thus the $K$ triangles $\triangle_k$ in the triangulation are indexed $k=0,\dots,K-1$.  The $N$ nodes are located at $\bx_i=(x_i,y_i)$ for $i=0,\dots,N-1$. 

In our $P^1$ finite element method the functions are linear on each $\triangle_k$ and continuous on the whole of $\overline\Omega$.  Such functions have three degrees of freedom on each $\triangle_k$, which one may think of as the coefficients in the linear formula $a + b x + c y$.  There are, however, more convenient local bases than $\{1,x,y\}$, as follows.  For each node $j$ let $\psi_j(x,y)$ denote the basis (``hat'') function which is linear on each triangle, continuous on $\overline{\Omega}$, and equal to one at only one node $j$, so that
\begin{equation}
\psi_j(\bx_i) = \delta_{ij}.  \label{eq:un:hatdelta}
\end{equation}
See Figure \ref{fig:un:hatfunction} and compare Figure \ref{fig:of:q1hat}.  Functions $\psi_j$ are in $W^{1,2}(\Omega)$ \citep{Braess2007}, with piecewise-constant partial derivatives $\partial\psi_j/\partial x$ and $\partial\psi_j/\partial y$.  It follows easily from \eqref{eq:un:hatdelta} that the set $\{\psi_j\}_{j=0,\dots,N-1}$ is linearly-independent.

\begin{marginfigure}
\input{tmp/blob.1.elenum.tikz}

\medskip

\input{tmp/blob.1.nodenum.tikz}
\caption{A triangulation of the polygon in Figure \ref{fig:un:polygon}, with element (top) and node (bottom) numbering.  There are $K=15$ elements, $N=13$ nodes, and $n_D=4$ nodes in $\partial_D\Omega$.}
\label{fig:un:number-mesh}
\end{marginfigure}

These hat functions allow us to interpolate and extend the Dirichlet data $g_D$ from its nodal values on $\partial_D \Omega$ to $\overline\Omega$.  First number the $n_D$ nodes which are in the Dirichlet boundary by $\bx_{j_l} \in \partial_D\Omega$ for $l=0,\dots,n_D-1$.  Then let $\hat g_D \in C(\overline\Omega)$ be the piecewise-linear interpolant of $g_D$ which has value zero at all the nodes $\bx_j$ which are \emph{not} in the Dirichlet boundary $\partial_D \Omega$.  It has an easy expansion in hat functions:
\begin{equation}
\hat g_D(x,y) = \sum_{l=0}^{n_D-1} g_D(\bx_{j_l}) \psi_{j_l}(x,y). \label{eq:un:hatgdefine}
\end{equation}

Using $\psi_j$ and $\hat g_D$ we can now specify the finite-dimensional subspaces of $W^{1,2}(\Omega)$ for the method.  First, the \emph{test functions} are
\begin{align*}
S_{0}^h &= \Span\left<\psi_j \,:\, \bx_j \notin \partial_D \Omega\right> = \Span\left<\psi_j \,:\, j \neq j_l\right>,
\end{align*}
zero along $\partial_D \Omega$.  Second, the \emph{trial functions} have value $g_D$ along $\partial_D \Omega$,
\begin{equation}
S_{g}^h = \left\{\hat g_D + w \,:\, w \in S_{0}^h\right\}.
\end{equation}
Note that $S_{0}^h$ is a linear subspace of $W^{1,2}_0(\Omega)$ while $S_{g}^h$ is merely an affine subspace of $W^{1,2}(\Omega)$, and that
\begin{equation}
\dim(S_{0}^h)=\dim(S_{g}^h)=N-n_D.
\end{equation}

\begin{marginfigure}
\input{tikz/hatfunction.tex}
\caption{Hat functions $\psi_j$.}
\label{fig:un:hatfunction}
\end{marginfigure}

The FEM itself can now be stated.  It seeks $u^h\in S_{g}^h$ so that \eqref{eq:un:poissonweak} holds for all $v^h\in S_{0}^h$.  By linearity it suffices to consider only a basis of test functions $S_{0}^h$, so we require
\begin{equation}
\int_\Omega a(u^h) \grad u^h \cdot \grad \psi_i = \int_\Omega f(u^h) \psi_i + \int_{\partial_N\Omega} g_N \psi_i \label{eq:un:weakformhat}
\end{equation}
for all $i$ such that $\bx_i \notin \partial_D \Omega$.

On the other hand we may expand $u^h$ using $N-n_D$ unknown coefficients $u_j\in\RR$:
\begin{equation}
u^h(x,y) = \hat g_D(x,y) + \sum_{\bx_j \notin \partial_D \Omega} u_j\, \psi_j(x,y). \label{eq:un:uhexpand}
\end{equation}
The coefficients $u_j$ in \eqref{eq:un:uhexpand} are the unknowns.

Given the triangulation $\mathcal{T}_h$ of $\Omega$ and the data of the problem, namely the functions $a$, $f$, $g_D$, and $g_N$, the complete specification of the FEM solution $u^h$ is given by equations \eqref{eq:un:hatgdefine}, \eqref{eq:un:weakformhat}, and \eqref{eq:un:uhexpand}.  This FEM problem can be shown to be well-posed, in the linear case at least, by the same theory that applies to the continuum problem.

As a next step in the linear case it is common to write system \eqref{eq:un:weakformhat} and \eqref{eq:un:uhexpand} in matrix-vector form as $A \bu = \bb$, and then to assemble the \emph{stiffness matrix} $A$ \citep{Elmanetal2005}.  However, as said earlier, we will not assemble a matrix until we have an initial, verified numerical solution.  Following the pattern established since Chapter \ref{chap:nl}, we first implement equation \eqref{eq:un:weakformhat} as a residual function $\bF(\bu)$, a \PETSc \pSNES call-back, in which the input $\bu$ is the representation of $u^h$ as a vector of nodal values.  In evaluating $\bF$ we use \eqref{eq:un:uhexpand} to get point values of $u^h$, and its gradient $\grad u^h$, on the interior of triangles.  These point values allow quadrature, similar to that in Chapter \ref{chap:of}, to approximate the integrals in \eqref{eq:un:weakformhat}.  Implementing a residual in the linear case is mathematically equivalent to assembling $A$ and $\bb$, but the residual-evaluation code requires no direct contact with a \PETSc \pMat object.  Our solution can then be tested for correctness with a finite-differenced Jacobian (Chapter \ref{chap:nl}).  Once it is shown to work correctly, via comparison to an exact solution, then we re-consider matrix assembly for the Jacobian.

Before the code can be written we need to be more specific about what \eqref{eq:un:weakformhat} says on each element, and we need to read a triangular mesh into \PETSc data structures.


\section{Assembly of the residual equations}

In expression \eqref{eq:un:uhexpand}, $N-n_D$ values $\{u_j\}$ determine the FEM solution $u^h$.  However, it will be easier to write code if we \emph{increase} the size of the resulting nonlinear system up to dimension $N$ by including the nodal values in the Dirichlet boundary as unknowns:
\begin{equation}
\bu = \{u_j\}_{j=0}^{N-1} \in \RR^N  \label{eq:un:unknowns}
\end{equation}
To enforce the boundary conditions, the components of the residual corresponding to the Dirichlet boundary must be zero:
\begin{equation}
F_i(\bu) = u_i - g_D(\bx_i) \qquad \text{ if } \bx_i \in \partial_D\Omega.  \label{eq:un:dirichletresiduals}
\end{equation}

Triangulation $\mathcal{T}_h$ covers $\Omega$ with non-overlapping triangles, so we can write integral \eqref{eq:un:weakformhat} as a sum over elements.  In fact, for each $k=0,\dots,K-1$ let
\begin{equation}
F_i^k(\bu) = \int_{\triangle_k} a(u^h) \grad u^h \cdot \grad \psi_i - f(u^h) \psi_i.  \label{eq:un:elementweakform}
\end{equation}
Suppose $n_N$ is the number of segments (edges) which are in the Neumann boundary.  For each segment $s_\nu$, $\nu=0,\dots,n_N-1$, let
\begin{equation}
\varphi_i^\nu = \int_{s_\nu} g_N \psi_i.  \label{eq:un:segmentweakform}
\end{equation}
(Note that $\varphi_i^\nu$ does \emph{not} depend on the solution $u^h$.)  Then \eqref{eq:un:weakformhat} becomes the statement that the following residual components are zero:
\begin{equation}
F_i(\bu) = \sum_{k=0}^{K-1} F_i^k(\bu) - \sum_{\nu=0}^{n_N-1} \varphi_i^\nu  \qquad \text{ if } \bx_i \notin \partial_D\Omega. \label{eq:un:elementwisesum}
\end{equation}
Together, equations \eqref{eq:un:dirichletresiduals} and \eqref{eq:un:elementwisesum} form a (generally) nonlinear system, of dimension $N$, which the \pSNES is asked to solve:
\begin{equation}
\bF(\bu)=0. \label{eq:un:fullsystem}
\end{equation}

Observe that $n_D$ is the number of \emph{nodes} in the Dirichlet boundary, whereas $n_N$ is the number of \emph{segments} in the Neumann boundary.  The former are degrees of freedom, while the latter are domains of integration.

Because the support of the hat function $\psi_i$ only overlaps with a few triangles $\triangle_k$, for each $i$ only a few values $F_i(\bu)$ and $\varphi_i^\nu$ are nonzero.  Also, only a few nodal values $\bu=\{u_j\}$ enter into $F_i^k(\bu)$, namely those values $u_j$ such that the support of $\psi_j$ overlaps with $\psi_i$.  These facts make \eqref{eq:un:fullsystem} a sparse nonlinear system.

We will compute the element integrals \eqref{eq:un:elementweakform} by referring $\triangle_k$ to a reference triangle $\triangle_\ast$ with vertices $(0,0),\,(1,0),\,(0,1)$, as shown in Figure \ref{fig:isoparametric}.  (In Chapter \ref{chap:of} we did something similar for quadrilaterals.)  If $\triangle_k$ has vertices $(x_0,y_0),\,(x_1,y_1),\,(x_2,y_2)$ then the linear map from $\triangle_\ast$ to $\triangle_k$ is
\begin{align}
x(\xi,\eta) &= x_0 + (x_1-x_0) \xi + (x_2-x_0) \eta, \label{eq:un:trianglemap} \\
y(\xi,\eta) &= y_0 + (y_1-y_0) \xi + (y_2-y_0) \eta. \notag
\end{align}
The Jacobian determinant of this map, needed for integrating, is constant on each element.  Its magnitude $2|\triangle_k|$ is the ratio of the triangle areas.

\begin{marginfigure}
\input{tikz/isoparametric.tex}
\caption{Mapping of a triangle $\triangle_k$ from the reference triangle $\triangle_\ast$.}
\label{fig:isoparametric}
\end{marginfigure}

On $\triangle_\ast$ any linear function is a linear combination of three local (nodal) basis functions:
\begin{equation}
\chi_0(\xi,\eta) = 1-\xi-\eta, \qquad \chi_1(\xi,\eta) = \xi, \qquad \chi_2(\xi,\eta) = \eta. \label{eq:un:chiformulas}
\end{equation}
If $\bx_i\in\overline{\triangle_k}$ then $\psi_i$ satisfies
\begin{equation}
\psi_i(x(\xi,\eta),y(\xi,\eta)) = \chi_\ell(\xi,\eta) \label{eq:un:psichimap}
\end{equation}
for all $(\xi,\eta)\in\triangle_\ast$, where vertex $\ell \in \{0,1,2\}$ of $\triangle_\ast$ maps to $\bx_i$.

Recalling both the change-of-variables formula for integrals and the chain rule, we can write
\begin{equation}
F_i^k(\bu) = 2 |\triangle_k| \int_{\triangle_\ast} H_\ell^k(\bu,\xi,\eta)\,d\xi\,d\eta \label{eq:un:elementintegralreference}
\end{equation}
where the integrand is
\begin{equation}
H_\ell^k(\bu,\xi,\eta) = \left[a(u^h) \grad u^h \cdot \grad \psi_i - f(u^h) \psi_i\right]_{\triangle_\ast}.  \label{eq:un:elementintegrand}
\end{equation}
Here vertex $\ell$ of $\triangle_\ast$ corresponds to the node $\bx_i$.  Note that ``$\grad$'' in \eqref{eq:un:elementintegrand} refers to derivatives in variables $x,y$.  Exercises \ref{chap:un}.\ref{exer:un:gradientdetails} and \ref{chap:un}.\ref{exer:un:elementintegranddetails} addresses the remaining details implicit in \eqref{eq:un:elementintegralreference} and \eqref{eq:un:elementintegrand}.

As in Chapter \ref{chap:of}, integrals \eqref{eq:un:elementintegralreference} are approximated using quadrature.  Generally, if there are $Q$ quadrature points $(\xi_q,\eta_q) \in \triangle_\ast$ with weights $w_q$ then
\begin{equation}
F_i^k(\bu) \approx 2 |\triangle_k| \sum_{q=0}^{Q-1} w_q H_\ell^k(\bu,\xi_q,\eta_q). \label{eq:un:elementquadraturereference}
\end{equation}
We use symmetric quadrature rules constructed for the reference triangle $\triangle_\ast$ \citep{Dunavant1985}.  (Unsymmetric quadrature rules based on tensor products of one-dimensional integrals \citep{KarniadakisSherwin2013} are an alternative.)  Table \ref{tab:un:quadrature} shows the degree $1,2,3$ Gaussian rules with $Q=1,3,4$ points, respectively (Exercise \ref{chap:un}.\ref{exer:un:checkquadrature}).  Note that the sum of the weights is $1/2$ because $|\triangle_\ast|=1/2$.

\begin{table}[h]
\vspace{0.1in}

\begin{tabular}{lccc}
degree & $Q$ & weights $w_q$ & nodes $(\xi_q,\eta_q)$ \\ \hline
$1$ & $1$ & $1/2$ & $(1/3,1/3)$ \\ \hline
$2$ & $3$ & \begin{tabular}{c}
            $1/6$ \\
            $1/6$ \\
            $1/6$
            \end{tabular} & \begin{tabular}{c}
            $(1/6,1/6)$ \\
            $(2/3,1/6)$ \\
            $(1/6,2/3)$
            \end{tabular} \\ \hline
$3$ & $4$ & \begin{tabular}{c}
            $-27/96$ \\
            $25/96$ \\
            $25/96$ \\
            $25/96$
            \end{tabular} & \begin{tabular}{c}
            $(1/3,1/3)$ \\
            $(1/5,1/5)$ \\
            $(3/5,1/5)$ \\
            $(1/5,3/5)$
            \end{tabular}
\end{tabular}

\vspace{0.1in}
\caption{Symmetric quadrature rules with $Q$ points on the reference triangle $\triangle_\ast$.  See \eqref{eq:un:elementquadraturereference}.} \label{tab:un:quadrature}
\end{table}

For the Neumann boundary contributions we use the midpoint rule; compare Exercise \ref{chap:un}.\ref{exer:un:gaussneumann}.  Observe that hat function $\psi_i$ has value $1/2$ at the midpoint of an edge incident to $\bx_i$.  If $(x_m,y_m)$ is this midpoint, $|s_\nu|$ is the length of segment $s_\nu$, and $\bx_i\in \overline{s_\nu}$ then
\begin{equation}
\varphi_i^\nu \approx g_N(x_m,y_m) \psi_i(x_m,y_m) |s_\nu| = \frac{1}{2} |s_\nu|\, g_N(x_m,y_m). \label{eq:un:segmentquadrature}
\end{equation}
Otherwise, if $\bx_i \notin \overline{s_\nu}$, then $\varphi_i^\nu=0$.


\section{Example problems}

Now let us set up some simple cases with known exact solutions.  The three cases test the implementation of the PDE and the boundary conditions.  Two problems are linear and one is nonlinear.  Our goal for these problems is that the measured numerical errors from the FEM will only converge at the optimum, theoretical rate $O(h^2)$ \citep{Elmanetal2005} if our implementation is correct.

\begin{figure}
\input{tikz/trap.tex}
\caption{Exact solution cases $0$ and $1$ solve Poisson equations on a trapezoidal region $\Omega$.  Boundary subsets $\partial_D\Omega$, $\partial_N \Omega$ are as indicated.  See \texttt{trap.poly} in Code \ref{code:trappoly}.}
\label{fig:un:trap}
\end{figure}

All three cases are based on the same manufactured solution
\begin{equation}
  u_{\text{exact}}(x,y) = 1 - y^2 - \frac{1}{4} y^4. \label{eq:un:exactsolution}
\end{equation}
This formula also computes the Dirichlet boundary values $g_D(x,y)$ in all cases, but other details are case-specific:
\begin{itemize}
\item[case $0$:] \emph{Linear}.  Use Figure \ref{fig:un:trap} boundary conditions.  Noting $\partial u_{\text{exact}}/\partial n = -\partial u_{\text{exact}}/\partial y = 0$ on the Neumann boundary $\partial_N \Omega = \{y=0\}$, let $g_N=0$.  Let $a=1$ and determine $f$ by differentiating the exact solution, so that $f(x,y) = 2 + 3 y^2$.
\item[case $1$:] \emph{Nonlinear}.  Again use Figure \ref{fig:un:trap} boundary conditions and $g_N=0$.  However, let $a(u) = 1+u^2$ and compute the corresponding $f(u)$ by differentiation.
\item[case $2$:] \emph{Non-homogeneous Neumann}.  Use Figure \ref{fig:un:trapneu} boundary conditions.  Let $a$, $f$ be the same as in case $0$.  Determine the (non-zero) value $g_N$ by differentiating $u_{\text{exact}}$ along the Neumann boundary, a line segment with outward unit normal vector $\bn = \left<1/1\right>/\sqrt{2}$.
\end{itemize}
See \texttt{c/\CODELOC cases.h} (not shown) for all remaining details.

\begin{figure}
\input{tikz/trapneu.tex}
\caption{Case $2$ uses the same region as in cases $0$ and $1$, but with different boundary conditions.  See \texttt{c/\CODELOC meshes/trapneu.poly} (not shown).}
\label{fig:un:trapneu}
\end{figure}


\section{Triangulations from \Triangle}

\PETSc does not include tools for triangulating regions of the plane, that is, for the generation of an unstructured mesh.  We use the widely-available \Triangle\sidenote{See \href{http://www.cs.cmu.edu/~quake/triangle.html}{www.cs.cmu.edu/$\sim$quake/ triangle.html} for documentation.} software \citep{Shewchuk1996} for this task.  \Triangle is limited to 2D, but the ASCII files it generates have straightforward details.

\inputwhole{../c/\CODELOC/meshes/trap.poly}{\CODELOC meshes/trap.poly}{A description of the boundary polygon in Figure \ref{fig:un:trap}, suitable for reading by \Triangle.}{code:trappoly}

\Triangle takes as input an ASCII file describing a polygonal region $\Omega$ by giving the coordinates of the nodes in $\partial \Omega$.  Additional integer flags (``markers'') classify the vertices or segments on the boundary.  For example, the input file \texttt{trap.poly} (Code \ref{code:trappoly}) generates the polygon shown in Figure \ref{fig:un:trap}.

The triangulation shown in Figure \ref{fig:un:trapone} came from applying \Triangle to \texttt{trap.poly}, as follows.  We ask for a polygon output file (option \texttt{-p}), relatively-uniform triangles (\texttt{-q} for ``quality-checked''),\sidenote{I.e.~with no interior angles less than $20^\circ$ \citep{Shewchuk1996}.} and triangles with a maximum area (\texttt{-a}) of $0.5$:
\begin{cline}
$ cd c/ch7/meshes
$ triangle -pqa0.5 trap
\end{cline}
%$
The command generates three ASCII files, \texttt{trap.1.node}, \texttt{trap.1.ele}, and \texttt{trap.1.poly}; see Codes \ref{code:traponenode}--\ref{code:traponepoly}.  They define the new node locations, elements (triples of nodal indices), and segments in the polynomial boundary (pairs of nodal indices), respectively.  As seen in Figure \ref{fig:un:trapone}, this triangulation has $N=8$ nodes, $K=6$ elements, $P=8$ boundary segments, $n_D=5$ Dirichlet nodes, and $n_N=4$ segments in the Neumann boundary.

\begin{figure}
\input{tmp/trap.1.tikz}
\caption{The triangulation described by \texttt{trap.1.\{node,ele,poly\}}.}
\label{fig:un:trapone}
\end{figure}

\inputwhole{misc/trap.1.node}{\CODELOC meshes/trap.1.node}{Node locations and nodal boundary flags for the mesh in Figure \ref{fig:un:trapone}.}{code:traponenode}

By giving value ``$2$'' to the Dirichlet nodes in the original \texttt{trap.poly} input, and because \Triangle itself uses ``$0$'' for non-boundary and ``$1$'' for otherwise un-flagged boundary nodes, we have this boundary flag scheme:
\begin{itemize}
\item[$0=$] interior node,
\item[$1=$] Neumann boundary segment (or node), and
\item[$2=$] Dirichlet boundary node (or segment).
\end{itemize}
Observe that, though \texttt{trap.poly} describes the boundary using only 4 segments, additional boundary nodes and segments have been added in \texttt{trap.1.node}.

\inputwhole{misc/trap.1.ele}{\CODELOC meshes/trap.1.ele}{Element index triples for the mesh in Figure \ref{fig:un:trapone}.}{code:traponeele}

We will test the FEM on a sequence of refined grids generated by \Triangle.  For an example, the command
\begin{cline}
$ triangle -rpqa0.1 trap.1
\end{cline}
%$
generates ASCII files \texttt{trap.2.\{node,ele,poly\}} with $N=33$ nodes, $K=33$ elements, and $P=19$ boundary segments (Figure \ref{fig:un:traptwo}).  Refinement (\texttt{-r}) here means that \emph{nodes} in the \texttt{trap.1} files are retained, but there is no simple inclusion relationship for the interior edges or triangles.  We also see that the symmetry of the \texttt{trap.1} mesh was merely fortuitous as symmetries in the input polygon are not preserved by the \Triangle algorithms.

\inputwhole{misc/trap.1.poly}{\CODELOC meshes/trap.1.poly}{Refined polygon, including segment boundary flags, for the mesh in Figure \ref{fig:un:trapone}.}{code:traponepoly}

\begin{figure}
\input{tmp/trap.2.tikz}
\caption{A refined triangulation.}
\label{fig:un:traptwo}
\end{figure}

\Triangle includes a minimal visualization tool.  The command
\begin{cline}
$ showme trap
\end{cline}
%$
displays the boundary polygon from \texttt{trap.poly} and all generated levels of the triangulation (i.e.~\texttt{trap.\{1,2\}.\{node,ele,poly\}} for now).


\section{Loading the mesh into \PETSc \pVecs and \pISs}

Our plan is to traverse the elements $\triangle_k \in \mathcal{T}_h$, and the Neumann boundary segments $s_\nu$, so as to compute \eqref{eq:un:elementquadraturereference} and \eqref{eq:un:segmentquadrature}.  The traversal is reasonably fast if the mesh data are stored in \PETSc objects.  We first convert the \Triangle-generated ASCII files into \pVecs and \pISs using a Python script \texttt{tri2petsc.py}.

An abstract description clarifies this step.  There are two kinds of ``data'' to describe a mesh, \emph{geometrical} and \emph{topological}.  Here the geometry is simply the nodal locations, pairs of real numbers for each node.  We store these coordinates in a length $2N$ sequential \pVec.  For the topology we have descriptions of which elements (triangles) are incident to which nodes (vertices).  This task only requires integer indices.  Each element is given by a triple of integers, each being a node index in the range $0,\dots,N-1$.  Similarly, a segment of the polygonal boundary is simply a pair of indices identifying the endpoint nodes.

The \PETSc \pIS ``index set'' type is convenient for storing these indices.  The reader may for now regard an \pIS simply as an ``integer-valued \pVec.''\sidenote{In this Chapter we do not exploit the ``main purpose'' of an \pIS, namely in distributed (multi-process) indexing.}  The \pIS storing the element index triples holds $3K$ integers and the one for boundary segments holds $2P$ integers.

Some care is needed in recording the Dirichlet and Neumann parts of the boundary.  First, one cannot tell if an edge is a boundary segment just from whether the endpoints are in the boundary.\sidenote{For example, the edge from node 5 to node 7 in Figure \ref{fig:un:number-mesh} is not a boundary segment.}  Second, even if the endpoints of a boundary segment are in the (closed) Dirchlet boundary, the segment itself might be in the (relatively-open) Neumann boundary.  Therefore, despite the apparent redundancy, we will separately store flags for the \emph{nodes}, indicating whether they are interior ($0$) or Neumann boundary ($1$) or Dirichlet boundary ($2$), and for the \emph{segments} on the boundary, either $1$ for Neumann or $2$ for Dirichlet.  This scheme is already shown in \Triangle outputs above (Codes \ref{code:traponenode}--\ref{code:traponepoly}).  Two more \pISs are used to store these flags.

Thus the Python script \texttt{tri2petsc.py} (not shown) reads three files in \Triangle-generated ASCII format, as described above, with extensions \texttt{.node,.ele,.poly}.  Then it writes two files in \PETSc binary format with extensions \texttt{.vec,.is}.  The first output file holds a \pVec with the node coordinates.  The second output file holds four \pISs (element triples, nodal boundary flags, boundary segment pairs, and boundary segment flags).

Let's try it out.  Because \texttt{tri2petsc.py} uses Python modules from the \PETSc source directory, we first generate some symbolic links:
\begin{cline}
$ cd c/ch7/
$ ln -s ~/petsc/bin/petsc_conf.py
$ ln -s ~/petsc/bin/PetscBinaryIO.py
$ ./tri2petsc.py meshes/trap.1 meshes/trap.1
\end{cline}
This generates two files \texttt{meshes/trap.1.\{vec,is\}}.

\cinputpart{um.h}{\CODELOC}{\texttt{UM} is an unstructured-mesh data type.}{I}{//STARTSTRUCT}{//ENDSTRUCT}{code:umstruct}

Our C code is, for the first time in the book, designed in a modular, instead of monolithic, way.  We separate the representation of the mesh, and the functions that read it in from files, from the tasks of computing the residual and setting up the \PETSc solver.  Thus the reader should examine these files in \texttt{c/ch7/}:
\begin{itemize}
\item \texttt{um.h} and \texttt{um.c}:\quad  Declares a simple unstructured-mesh representation as a C \texttt{struct} and provides an interface for it.  The major functions read a mesh from binary files and view it.
\item \texttt{cases.h}:\quad  Exact solutions and boundary conditions for the problem cases above.
\item \texttt{unfem.c}:\quad  Contains a residual evaluation function.  Also reads options, calls \texttt{UM} functions to read the mesh, sets up a \pSNES solver object, runs the solver, and reports the numerical error.
\end{itemize}

Details of the mesh representation are given next, before addressing the approximation and solution of the PDE problem in the main program \texttt{unfem.c}.  We will not show file \texttt{cases.h} at all because it is adequately-documented by the earlier text on the example problem cases.

The \texttt{UM} (``unstructured mesh'') \texttt{struct} is declared in Code \ref{code:umstruct}.  The ``methods'' for this ``object'' are declared in Code \ref{code:umdeclare}.  The order in which they are shown suggests the order in which they are typically called.  \texttt{UMInitialize()} should be called before anything else, and \texttt{UMDestroy()} last.  Function \texttt{UMReadNodes()} should be called before \texttt{UMReadISs()}; these load binary data using \PETSc functions  \texttt{VecLoad()} and \texttt{ISLoad()}, respectively.
We do not display the implementations of these functions, in file \texttt{c/ch7/um.c}, as this would be more tedious than illuminating.

Despite our attempt at modularity, our representation of an unstructured mesh is deliberately simple and even naive.  It provides a suggestive example which motivates Chapter \ref{chap:dp} coverage of much more advanced \PETSc support for unstructured meshes.

\cinputpart{um.h}{\CODELOC}{The ``methods'' for the \texttt{UM} unstructured-mesh data type.}{II}{//STARTDECLARE}{//ENDDECLARE}{code:umdeclare}


\section{Initial implementation}

With an unstructured mesh in hand we can return to implementing the FEM.  We build a \pSNES-using code\sidenote{The reader might observe that, in terms of \PETSc objects and calls, \texttt{unfem.c} is similar to \texttt{ecjac.c} in Chapter \ref{chap:nl} in the sense that there is no use of a \PETSc interface for grid topology.} which works, called \texttt{c/\CODELOC unfem.c}.  The most important parts are a residual-computation function \texttt{FormFunction()} and a \texttt{main()} function.  Figure \ref{fig:un:unfemstack} shows the structure, including the approximate-Jacobian \texttt{FormPicard()} which we implement later.  Extracts from \texttt{c/ch7/unfem.c}, displaying all essentials of the initial implementation, are shown in Codes \ref{code:unfemctx}--\ref{code:unfemelementresiduals}.

\begin{figure}
\begin{tikzpicture}[scale=0.8,
                    >={Latex[length=2mm]},
  component/.style={
     rectangle,draw,fill=white,align=center,line width=1pt},
  userfcn/.style={
     rounded corners,draw,fill=white,draw,align=center,line width=1pt,font={\itshape,\normalsize}}]

\draw[line width=1pt] (3,7) node[userfcn,minimum width=105mm] (usercode) {user code \\ \vspace{15mm}};

\draw[line width=1pt] (0,7.2) node[userfcn] (rescode) {residual \emph{\texttt{FormFunction()}}};
\draw[line width=1pt] (5.2,6.2) node[userfcn] (jaccode) {approximate Jacobian \emph{\texttt{FormPicard()}}};

\draw[line width=1pt] (-1,4) node[component] (snes) {\complabel{\pSNES}{nonlinear solver}};
\draw[line width=1pt] (-1,2) node[component] (ksp)  {\complabel{\pKSP}{linear solver}};
\draw[line width=1pt] (-1,0) node[component] (pc)   {\complabel{\pPC}{preconditioner}};

\draw[line width=1pt] (2,2) node[component] (matj)   {\usedlabel{\pMat}{Jacobian}};
\draw[line width=1pt] (3.5,0) node[component] (vecs)   {\pVecs \\ \footnotesize  \emph{node coordinates, solution}};
\draw[line width=1pt] (7.5,0) node[component] (iss)   {\pISs \\ \footnotesize  \emph{indices, bdry flags}};

\path
   ([xshift=-10em]usercode.south) edge[->] node {} (snes)
   ([xshift=0em]usercode.south) edge[->] node {} ([xshift=2em]vecs.north)

   (rescode.south) edge[->,bend left] node {} (vecs.north)
   ([xshift=-2em]rescode.south) edge[->] node {} (iss.north)

   (jaccode.south) edge[->] node {} (matj)
   ([xshift=2em]jaccode.south) edge[->] node {} ([xshift=4em]vecs.north)
   ([xshift=4em]jaccode.south) edge[->] node {} ([xshift=2em]iss.north)

   (snes) edge node {} (ksp)
   (ksp) edge node {} (pc);
\end{tikzpicture}
\caption{The structure of \texttt{unfem.c}.}
\label{fig:un:unfemstack}
\end{figure}

So that the residual-evaluation function \texttt{FormFunction()} has access to functions $a$, $f$, $g_D$, $g_N$ in FEM \eqref{eq:un:weakformhat}, we define a solution context \texttt{struct unfemCtx} in Code \ref{code:unfemctx}.  This \texttt{struct} also includes the mesh, that is, it includes a pointer to a \texttt{UM} instance.

\cinputpart{unfem.c}{\CODELOC}{Context for solving FEM \eqref{eq:un:weakformhat}, \eqref{eq:un:uhexpand} on an unstructured mesh.}{I}{//STARTCTX}{//ENDCTX}{code:unfemctx}

Only an extract of the \texttt{main()} function is displayed here (Code \ref{code:unfemmain}).  We do not show the first actions of \texttt{main()}, which are to read options and choose appropriate functions $a,f,g_D,g_N$ for the problem case.  The lines shown in Code \ref{code:unfemmain} start with reading a mesh from \PETSc binary files via calls to the ``methods'' of the \texttt{UM} object.  Then \pVecs are allocated and the \pSNES solver is configured.  We set a call-back to \texttt{FormFunction()} by using \texttt{SNESSetFunction()}.

\cinputpart{unfem.c}{\CODELOC}{An extract of \texttt{main()}: read the mesh, set-up \pVecs, configure \pSNES, and reset the default \pKSP and \pPC for our symmetric, positive-definite problem.}{II}{//STARTMAININITIAL}{//ENDMAININITIAL}{code:unfemmain}

Though we do not, for now, need to do any work to assemble it, the symmetry and positive-definiteness of the Jacobian matrix is already relevant here.  In the linear case, in which $\partial a/\partial u=0$ and $\partial f/\partial u=0$ in \eqref{eq:un:poissonweak}, the Jacobian $J_{ij} = \partial F_i/\partial u_j$ is symmetric and positive-definite.\sidenote{We prove the claim below in the subsection on assembling an approximate Jacobian.}  This fact is sufficient reason to reset the default \pKSP and \pPC types to the conjugate gradient (CG) and incomplete-Cholesky (ICC) types, respectively.  This is done in Code \ref{code:unfemmain} by first getting a pointer to the \pKSP inside the \pSNES---see Figure \ref{fig:un:unfemstack}---and then setting its type.  Getting a pointer to the \pPC inside the \pKSP then allows us to set the \pPC type as well.

The extract in Code \ref{code:unfemmain} also shows that an analytical Jacobian \pMat \texttt{A} is allocated, and a \pSNES call-back is set with \texttt{SNESSetJacobian()}.  We return to these actions below, but for now we note they are ignored if \texttt{-snes\_fd} is used, as we do initially.

\cinputpart{unfem.c}{\CODELOC}{Our FEM uses local basis functions $\chi_\ell$ and some quadrature tools.}{III}{//STARTFEM}{//ENDFEM}{code:unfemfem}

Code \ref{code:unfemfem} shows FEM details (``tools'') appearing in \texttt{c/ch7/unfem.c}.  For example, the first few displayed lines correspond to equation \eqref{eq:un:chiformulas} for the local basis functions $\chi_\ell(\eta,\xi)$.  There are also functions to evaluate the gradients $\grad \chi_\ell$ and linear combinations $\sum_\ell v_\ell \chi_\ell$.  The remaining lines define arrays for the quadrature rules in Table \ref{tab:un:quadrature}.

The C function that evaluates $\bF(\bu)$ is called \texttt{FormFunction()}.  It is shown in Codes \ref{code:unfembdryresiduals}--\ref{code:unfemelementresiduals}.  Note that \texttt{Vec u} is an input, and thus it is accessed using a \texttt{const double *} pointer and \texttt{VecGetArrayRead()}, while \texttt{Vec F} is an output accessed using a \texttt{double *} pointer and \texttt{VecGetArray()}.  Function \texttt{UMGetNodeCoordArrayRead()} gives a pointer to an array of \texttt{Node}s, simply a two-member \texttt{struct} holding the coordinates of a point in $\RR^2$ (not shown).  When accessing indices we use \texttt{ISGetIndices()} instead.  All of these \texttt{Get} functions have a matching \texttt{Restore}.

\cinputpart{unfem.c}{\CODELOC}{\texttt{FormFunction()} first evaluates \eqref{eq:un:dirichletresiduals} and \eqref{eq:un:segmentweakform} for the boundary contributions.}{IV}{//STARTBDRYRESIDUALS}{//ENDBDRYRESIDUALS}{code:unfembdryresiduals}

\cinputpart{unfem.c}{\CODELOC}{Next, \texttt{FormFunction()} traverses the elements to compute residuals \eqref{eq:un:elementweakform}.}{V}{//STARTELEMENTRESIDUALS}{//ENDELEMENTRESIDUALS}{code:unfemelementresiduals}

Code \ref{code:unfembdryresiduals} show that \texttt{FormFunction()} first loops through all $N$ nodes and computes the residual \eqref{eq:un:dirichletresiduals} for each node in the Dirichlet boundary.  Then it loops through all $P$ segments of polygon $\partial \Omega$ and computes the Neumann boundary integrals \eqref{eq:un:segmentweakform} by the midpoint rule.  (These are nonzero for the nodes $\bx_i$ such that the support of the hat function $\psi_i$ has nontrivial overlap (intersection) with a Neumann segment $s_\nu$.)

The rest of \texttt{FormFunction()}, shown in Code \ref{code:unfemelementresiduals}, implements \eqref{eq:un:elementweakform} and \eqref{eq:un:elementwisesum}.  The integrand function $H_\ell^k$ in \eqref{eq:un:elementintegrand} and the quadrature \eqref{eq:un:elementquadraturereference} are computed according to details laid-out in Exercises \ref{chap:un}.\ref{exer:un:gradientdetails} and \ref{chap:un}.\ref{exer:un:elementintegranddetails}.

Before we do initial testing it might be wise for the reader to browse the files in \texttt{c/ch7/}, including \texttt{unfem.c}.


\section{Initial testing}

Our first run\sidenote{Showing the actual process of debugging in a textbook is difficult, and not really attempted.  Bugs occurred and were found!} uses the coarse triangulation in Figure \ref{fig:un:trapone}.  Because we initially test only the residual evaluation function \texttt{FormFunction()} and not an analytical Jacobian, we add \texttt{-snes\_fd}:
\begin{cline}
$ cd c/ch7/
$ make unfem
...
$ ./unfem -un_mesh meshes/trap.1 -snes_fd
case 0 result for N=8 nodes with h = 1.414e+00 :  |u-u_ex|_inf = 0.230159
\end{cline}
%$
Note that \texttt{unfem} describes the mesh by the number of nodes $N$ and the maximum triangle side length $h$.  Also \texttt{unfem} defaults to the ``case $0$'' exact solution---see the description of this linear problem on page \pageref{eq:un:exactsolution}---and quadrature of degree $1$.

Next we refine the mesh and meanwhile examine the symmetry and sparsity pattern of the Jacobian using X windows.  We have already generated the mesh (\texttt{trap.2} in Figure \ref{fig:un:traptwo}), but it needs to be converted to \PETSc binary files:
\begin{cline}
$ ./tri2petsc.py meshes/trap.2 meshes/trap.2
$ ./unfem -un_mesh meshes/trap.2 -snes_fd -mat_view draw -draw_pause 2
case 0 result for N=33 nodes with h = 6.212e-01 :  |u-u_ex|_inf = 0.0289678
\end{cline}
%$
The middle frame of Figure \ref{fig:un:unfem-matsparsity} shows the result, sandwiched between comparable results for a coarser and a finer mesh.  Note the error is an order of magnitude smaller than with mesh \texttt{trap.1}.

\begin{figure}
\includegraphics[width=0.31\textwidth]{figs/trap1mat} \, \includegraphics[width=0.31\textwidth]{figs/trap2mat} \, \includegraphics[width=0.31\textwidth]{figs/trap3mat}
\caption{Matrix sparsity patterns from \texttt{unfem.c} applied to the meshes \texttt{trap.1,2,3} with $N=8,33,136$ nodes, respectively.}
\label{fig:un:unfem-matsparsity}
\end{figure}

The verification test we care about is whether the error decreases at the theoretically-expected rate as the mesh is refined.  We start by writing the following snippet of Bash code for nine levels of refined grids \texttt{trap.1}--\texttt{trap.9}:
\begin{code}
area[0]=0.5
area[1]=0.1
area[2]=0.02
area[3]=0.005
area[4]=0.001
area[5]=0.0002
area[6]=0.00005
area[7]=0.00001
area[8]=0.000002
triangle -pqa${area[0]} meshes/trap
./tri2petsc.py meshes/trap.1 meshes/trap.1
for (( N=1; N<9; N++ )); do
    triangle -rpqa${area[$N]} meshes/trap.$N    # generate .poly,.node,.ele
    OUT=meshes/trap.$((N+1))
    ./tri2petsc.py $OUT $OUT                    # generate .vec,.is
done
\end{code}
%$

A bit of testing with these meshes shows, however, that \texttt{-snes\_fd} runs are far too slow.  The runs fail with a too-many-evaluations error,\sidenote{Add \texttt{-snes\_converged\_reason} to see the error message.} for levels \texttt{trap.6}--\texttt{trap.9}.

On the other hand, the matrix-free Newton-Krylov method (see Chapter \ref{chap:nl}) is also available without an assembled Jacobian, i.e.~with option \texttt{-snes\_mf}.  For example, 
\begin{cline}
$ ./unfem -un_mesh meshes/trap.3 -snes_mf
case 0 result for N=136 nodes with h = 2.813e-01 :  |u-u_ex|_inf = 0.00777117
\end{cline}
%$

How far we can go with \texttt{-snes\_fd} and \texttt{-snes\_mf}?  The following snippet of Bash code uses those coarser meshes which complete without errors and in reasonable time for \texttt{-snes\_mf}:
\begin{code}
for (( N=1; N<=7; N++ )); do
    rm -f foo
    ./unfem -un_mesh meshes/trap.$N -snes_mf -log_view > foo
    grep "|u-u_ex|_inf" foo
    grep "SNESFunctionEval" foo
done
\end{code}
%$
A similar loop with ``\texttt{N=1; N<=5; N++}'' does the \texttt{-snes\_fd} runs.  The results are shown in Figure \ref{fig:un:unfem-fdmf}:

\begin{figure}
\includegraphics[width=\textwidth]{figs/unfem-fdmf}
\caption{Numerical error (left axis) and number of evaluations of \texttt{FormFunction()} (right axis) using \texttt{-snes\_fd} and \texttt{-snes\_mf}.}
\label{fig:un:unfem-fdmf}
\end{figure}

The errors in Figure \ref{fig:un:unfem-fdmf} from \texttt{-snes\_fd} and  \texttt{-snes\_mf} runs coincide for all grids where both methods complete successfully.  These results suggest convergence, but we will confirm the rate of convergence using an analytical Jacobian (below).

The runs so far slow-down dramatically with refinement.  The reason is not a mystery: Figure \ref{fig:un:unfem-fdmf} show the rapidly-growing number of residual evaluations as a function of the mesh spacing.  With \texttt{-snes\_fd} the number of evaluations of \texttt{FormFunction()} is proportional to the number of nodes/unknowns $N$ (Chapter \ref{chap:nl}).  By contrast, the number of residual evaluations for option \texttt{-snes\_mf} scales with the number of Krylov solver iterations.  Such iterations grow rapidly with refinement because, without an analytical Jacobian or an approximation thereof, we apply the Krylov method directly to the un-preconditioned linear system.


\section{Picard iteration as a Newton-like step}

Writing additional code for an analytical Jacobian is now well-motivated, but we do not construct the full Jacobian.  Instead we build a \emph{Picard matrix}, an approximate linearization.  This approximation is somewhat easier to construct than the Jacobian, which makes this approach a common technique.

To explain, observe that our nonlinear system \eqref{eq:un:fullsystem}, namely $\bF(\bu)=0$, has nearly-linear form already.  In fact, the FEM \eqref{eq:un:weakformhat}, \eqref{eq:un:uhexpand} has the form
\begin{equation}
A(\bu) \bu = \bb(\bu) \label{eq:un:picardformsystem}
\end{equation}
and the residual is just $\bF(\bu) = A(\bu) \bu - \bb(\bu)$.  The left side of \eqref{eq:un:weakformhat} contains all the derivative terms, which we group into the term $A(\bu) \bu$, which can then be regarded as a matrix-vector multiplication when computing $\bF(\bu)$.  The other zeroth-order terms go into $\bb(\bu)$.  In general, and in the ``case $1$'' test problem in particular, functions $A(\bu)$ and $\bb(\bu)$ are nonlinear.

Consider what happens when the matrix $A(\bu)$ and right-hand side $\bb(\bu)$ of \eqref{eq:un:picardformsystem} are ``frozen'' at some current iterate and the linear system solved for a new iterate:
\begin{equation}
A(\bu^k) \bu^{k+1} = \bb(\bu^k). \label{eq:un:picardnaive}
\end{equation}
This is the canonical form of a \emph{Picard iteration}.  Picard himself used the iteration to prove the existence of solutions to ODE IVPs (see Chapter \ref{chap:ts}) by demonstrating its convergence in that context \citep{HirschSmaleDevaney2004}.  Under strong hypotheses on the functions $A(\bu)\in\RR^{N\times N}$ and $\bb(\bu)\in\RR^{N}$, one can prove convergence of \eqref{eq:un:picardnaive}---see Exercise \ref{chap:un}.\ref{exer:un:picardconvergence}---but generally we have no more \emph{a priori} knowledge about the convergence of \eqref{eq:un:picardnaive} than we do for the Newton iteration (see Chapter \ref{chap:nl}).

At the level of the continuum equation, Picard iteration for our PDE problem \eqref{eq:un:poissonstrong} solves a linear PDE problem
\begin{equation}
-\Div\left(a(u^k) \grad u^{k+1}\right) = f(u^k) \label{eq:un:picardcontinuum}
\end{equation}
at each iteration.  Our approach to \eqref{eq:un:poissonstrong} therefore \emph{could} have been to only write code---i.e.~\texttt{FormFunction()}---for the linear case with $a=a(x,y)$, $f=f(x,y)$, and then to ``hard-code'' the Picard iteration, thinking of it as \eqref{eq:un:picardnaive} or \eqref{eq:un:picardcontinuum} according to taste.

Our actual approach is more powerful.  While we may do the Picard iteration \eqref{eq:un:picardnaive} as stated, in our approach we may also use \pSNES's line-search to globalize convergence and we can use the Picard matrix in pre-conditioning the Jacobian-free Newton-Krylov method---see below; recall Chapter \ref{chap:nl} discusses JFNK in some generality---so that we are actually running Newton's method while taking advantage of code which assembles the Picard matrix.  As a first step we must transform \eqref{eq:un:picardnaive} into a Newton-like form, so that \PETSc's \pSNES machinery applies.

Recall that the Newton method linearizes $\bF(\bu)=0$ into a system
\begin{equation}
J(\bu^k) \bs = -\bF(\bu^k),  \label{eq:un:newtonstep}
\end{equation}
for the step $\bs = \bu^{k+1}-\bu^k$.  Here we first subtract $A(\bu^k) \bu^k$ from each side of \eqref{eq:un:picardnaive},
\begin{equation*}
A(\bu^k) (\bu^{k+1}-\bu^k) = - \left(A(\bu^k) \bu^k - \bb(\bu^k)\right).
\end{equation*}
Note the appearance of the step $\bs$, and of the residual on the right side, so that we have
\begin{equation}
A(\bu^k) \bs = -\bF(\bu^k).  \label{eq:un:picardstep}
\end{equation}

Obviously, equation \eqref{eq:un:picardstep} is the same as \eqref{eq:un:newtonstep} but with the Picard matrix $A=A(\bu)$ replacing the Jacobian matrix $J=J(\bu)$.  For the linear case of PDE \eqref{eq:un:poissonstrong}, when $\partial a/\partial u=0$ and $\partial f/\partial u=0$, these matrices are the same, $A=J$.  For the general (nonlinear) case we expect $A$ to be a good spectral approximation (see Chapter \ref{chap:ls}) of $J$.  This is because $A$ and $J$ capture the highest-order derivative terms in the PDE in the same way.  These terms in the PDE dominate the locations of the largest eigenvalues, which in turn dominate the convergence of many Krylov methods (again, see Chapter \ref{chap:ls}).  We will see, in particular, that this approximation of the Jacobian is highly-effective when we use it as a pre-conditioner in the nonlinear ``case $1$.''


\section{Assembling and pre-allocating the Picard matrix}

Thus our plan is to write a function called \texttt{FormPicard()} which computes a \pMat \texttt{A} $=A(\bu)$ from the current estimate $\bu$ of the solution.  Then we will pass \texttt{FormPicard()} to \texttt{SNESSetJacobian()}.

Considering equations \eqref{eq:un:dirichletresiduals}, \eqref{eq:un:elementweakform}, and \eqref{eq:un:elementwisesum}, let
\begin{equation}
A_{ij}^k(\bu) = \int_{\triangle_k} a(u^h) \grad\psi_j \cdot \grad\psi_i \label{eq:un:picardentryelement}
\end{equation}
be the element-wise contribution.  The entries of $A$ are sums,
\begin{equation}
A_{ij}(\bu) =  \begin{cases}
               1, & i \in \partial_D\Omega \text{ or } j \in \partial_D\Omega, \\
               \sum_{k=0}^{K-1} A_{ij}^k(\bu), & \text{otherwise}.
               \end{cases} \label{eq:un:picardentry}
\end{equation}

As we have already computed integral \eqref{eq:un:picardentryelement}, namely in evaluating \eqref{eq:un:elementintegralreference}, we face a software-design choice.  We could perhaps re-write \texttt{FormFunction()} so that it also computes \texttt{A} as a side-effect, or we could factor out the code for the integrals \eqref{eq:un:picardentryelement} into a separate routine.  In fact we simply write a separate C function \texttt{FormPicard()}.  While this duplicates code, \texttt{FormFunction()} is already tested.  In any case, for fine meshes the cost of evaluating $\bF(\bu)$ and $A(\bu)$ is small compared to the solver (below).

Writing \texttt{FormPicard()} (not shown) is quite straightforward, as the finicky parts of residual evaluation relating to boundary conditions---see Codes \ref{code:unfembdryresiduals} and \ref{code:unfemelementresiduals}---are generally not needed.  One detail of note is that we call \texttt{MatSetValues()} with final option \texttt{ADD\_VALUES} to do sum \eqref{eq:un:picardentry}.

Correctly allocating memory for \pMat \texttt{A} \emph{does} matter, however.  In structured-grid cases in previous Chapters we have benefited, without being conscious of it, from \PETSc's accurate pre-allocation of memory for Jacobian matrices.  Such pre-allocation is hidden when using a \pDMDA structured grid.

Here we must do it ourselves.  Because all constructions in this Chapter are serial, the technique shown in Code \ref{code:unfemprealloc}, in which we call \texttt{MatSeqAIJSetPreallocation()} with an array \texttt{nnz} of integers, suffices.  We compute \texttt{nnz[n]}, the number of nonzeros in row $n$ of \texttt{A}, by traversing the elements just as in \texttt{FormFunction()}.  We decide whether to increment \texttt{nnz[n]} for a node according to whether it is in the Dirichlet boundary or not.  The only subtlety is that for an interior node with (edge) degree $d$ the number of incident elements is $d-1$ while for a Neumann boundary node the number of incident elements is $d-2$; in either case \texttt{nnz[n]} $=d+1$.

\cinputpart{unfem.c}{\CODELOC}{Efficiency requires pre-allocation of Picard matrix \pMat \texttt{A}.}{V}{//STARTPREALLOC}{//ENDPREALLOC}{code:unfemprealloc}

Pre-allocation of the sparse matrix \pMat \texttt{A} makes a difference.  For example, using a version of \PETSc configured with \texttt{--with-debugging=0}, we get 60 times faster performance with pre-allocation even on a medium-resolution mesh:
\begin{cline}
$ timer ./unfem -un_mesh meshes/trap.7 -un_noprealloc
case 0 result for N=46421 nodes with h = 2.210e-02 :  |u-u_ex|_inf = 6.55083e-05
real 56.30
$ timer ./unfem -un_mesh meshes/trap.7
case 0 result for N=46421 nodes with h = 2.210e-02 :  |u-u_ex|_inf = 6.55083e-05
real 0.97
\end{cline}

Code \ref{code:unfemmain} shows that \texttt{MatSetUp()} is the default alternative to calling \texttt{JacobianPreallocation()}.  The default allocation method in \PETSc, invoked by \texttt{MatSetUp()}, generates a dynamic list of matrix entries as they are inserted by \texttt{MatSetValues()}.  Then \texttt{MatAssemblyBegin/End()} allocates the matrix in its usual compressed sparse row storage format (Chapter \ref{chap:ls}) and then copies entries into that.  These actions are intrinsically expensive; they generate significant memory-access delays.


\section{Convergence and stage times}

Now we can measure convergence down to reasonably-fine grids.  Earlier we generated grids \texttt{trap.1}--\texttt{trap.9}.  The last of these has $N\approx 10^6$ nodes and a maximum element edge length of $h=4\times 10^{-3}$.

\begin{figure}
\includegraphics[width=\textwidth]{figs/unfem-error}
\caption{Numerical errors and convergence rates for exact solution cases $0$, $1$, $2$, as a function of the maximum mesh edge length $h$.}
\label{fig:un:unfem-error}
\end{figure}

Repeating the following loop for \texttt{CASE=0,1,2} generates the results seen in Figure \ref{fig:un:unfem-error}:
\begin{code}
for N in 1 2 3 4 5 6 7 8 9; do
    ./unfem -un_mesh meshes/trap.$N -un_case $CASE -log_view
done
\end{code}
Rates of convergence in the Figure are computed by logarithmic regression.
% using the results for meshes \texttt{trap.3}--\texttt{trap.8}.
This evidence suggests that our code has no substantial numerical bugs.  Though $h$ is the maximum edge length from \Triangle-generated meshes, in which we have little control of element shapes,\sidenote{Recall we impose an area constraint and a minimum angle condition.} the rates seen in Figure \ref{fig:un:unfem-error} are close to the theoretical rate $O(h^2)$ \citep{Braess2007}.

The runs above also used option \texttt{-log\_view}.  In \texttt{unfem.c} we added \emph{logging of stages} to the code using bracketing \PETSc commands like
\begin{code}
    PetscLogStagePush(stage);
    ... action ...
    PetscLogStagePop();
\end{code}
We made stages for reading the mesh, setting-up other data structures, residual evaluation, matrix evaluation, and calling the solver (i.e.~\texttt{SNESSolve()}).  While residual and Picard matrix evaluation happen ``inside'' the solver, they are counted separately.

\begin{figure}
\includegraphics[width=\textwidth]{figs/unfem-times}
\caption{Stage times for ``case $1$'': the solver versus everything else.}
\label{fig:un:unfem-times}
\end{figure}

The result timing these stages for the nonlinear ``case $1$'' runs, again using a \texttt{--with-debugging=0} version of \PETSc, is summarized in Figure \ref{fig:un:unfem-times}.  For the finer \texttt{trap.5}--\texttt{trap.9} grids\sidenote{The timing data for coarse grids is polluted by operating-system-level noise.} the lesson is quite clear: the solver, here ICC-preconditioned CG iteration, \emph{dominates over the cost of everything else}.  On the finest grid the solver takes about $98\%$ of the time.  Here ``everything else'' includes reading the mesh from a file, pre-allocating the \pMat, setting up \pVecs, evaluating the residual function $\bF(\bu)$, and assembling the matrix $A(\bu)$.  Note that on the finest grids there were only five evaluations of \texttt{FormFunction()} and four of \texttt{FormPicard()}.

Unsurprisingly, our performance focus in Chapter \ref{chap:sc} will be on the solver.


\section{Performance relative to \pDMDA structured grid}

It is a reasonable question to ask: Is this code ``efficient''?  At least there is a reasonable answer this question.  It assumes that \PETSc handles structured-grid problems efficiently.

We will run \texttt{unfem.c} on a structured-grid problem and compare the result to a code for the same structured grid which uses a \pDMDA structured grid.  First we generate a structured triangulation using Python script \texttt{genstructured.py} (not shown).  FIXME example shown

FIXME compares well in serial to Chapter 3 example


\begin{marginfigure}
\input{tmp/mesh.1.tikz}
\caption{A structured triangulation of the unit square with $N=16$ nodes.  The entire boundary is Dirichlet.}
\label{fig:structuredfem}
\end{marginfigure}

compare for \texttt{--with-debugging=0} build (note $1025^2=1050625$) from current directory \texttt{c/ch7/}:
\begin{cline}
$ ./genstructured.py meshes/square.10 1025
...
$ ./tri2petsc.py meshes/square.10 meshes/square.10
...
$ timer ./unfem -un_mesh meshes/square.10 -un_case 3
case 3 result for N=1050625 nodes with h = 1.381e-03 :  |u-u_ex|_inf = 9.89813e-08
real 24.47
\end{cline}
%$

versus with \pDMDA
\begin{cline}
$ cd ../ch3/
$ make poisson
...
$ timer ./poisson -da_refine 7 -ksp_type cg -pc_type icc
on 1025 x 1025 grid:  error |u-uexact|_inf = 5.29691e-08
real 18.67
\end{cline}
%$

\section{Toward parallel unstructured meshes}

FIXME: parallel approach could use \Triangle \texttt{.neigh} file as adjacency graph for elements, run \texttt{MatPartitioning} stuff (see manual), apply partitioning to get \pIS (or \texttt{AO}), and have nodes and edges follow along

FIXME: paraphrase Barry: The ``trick'' is that first partition the element across processes, then partition the vertices (nodal values) subordinate to the partitioning of the elements and then you renumber the elements and vertices so that the elements on the first process are numbered first, followed by the elements on the second process etc and similarly the vertices on the first process are numbered before the vertices on the second processes etc.  Each process loops over its elements computing the element stiffness/load and calling \texttt{MatSetValues/VecSetValues()} using the ``new'' numbering of the vertices.  The ``old'' numbering that was on the disk is not used in communicating with PETSc.

FIXME: see approach to mesh topology in chapter 10 of \citep{Loggetal2012}

%FIXME motivated by \citep{Loggetal2012}: replace $\bF(\bu)$ with $\bF(\bu;v)$; residual equation no longer requires basis of $S^h$ for its definition; advantages/disadvantages?


\section{Exercises}

\renewcommand{\labelenumi}{\arabic{chapter}.\arabic{enumi}\quad}
\renewcommand{\labelenumii}{(\alph{enumii})}
\begin{enumerate}
\item \label{exer:un:notminimization}  The text asserts that problems \eqref{eq:un:poissonstrong} and \eqref{eq:un:poissonweak} do not generally arise from a minimization principle, and this Exercise expands on the claim.  For simplicity suppose that $f$ is independent of $u$, use homogeneous Dirichlet boundary conditions on $\partial \Omega$, and feel free to consider only the 1D version of the problem.  First show, by following the technique that derived \eqref{eq:of:plapweakform}, that if $\partial a/\partial u \ne 0$ then the Euler-Lagrange equation of
\begin{equation}
  \tilde I[u] = \int_\Omega \frac{1}{2} a(u) |\grad u|^2 - f u,  \label{eq:un:nottheobjective}
\end{equation}
which represents merely a reasonable guess, is \emph{not} the weak form \eqref{eq:un:poissonweak}.  This does not exclude the possibility that some other minimization problem leads to \eqref{eq:un:poissonweak}, however.  Therefore, show next that if $\partial a/\partial u \ne 0$ then the residuals \eqref{eq:un:elementwisesum} satisfy
\begin{equation}
  \frac{\partial F_i(u)}{\partial u_j} \ne \frac{\partial F_j(u)}{\partial u_i} \label{eq:un:symmetryresidualsdonthave}
\end{equation}
for some $u$.  Explain why this excludes a minimization principle.
\item  \label{exer:un:gradientdetails}  For the map \eqref{eq:un:trianglemap} from $\triangle_\ast$ to $\triangle_k$, let
    $$J_k = \frac{\partial (x,y)}{\partial (\xi,\eta)} = \begin{pmatrix}
    x_1 - x_0 & x_2 - x_0 \\
    y_1 - y_0 & y_2 - y_0 \end{pmatrix}
    = \begin{pmatrix}
    \Delta x_1 & \Delta x_2 \\
    \Delta y_1 & \Delta y_2
    \end{pmatrix}$$
be the Jacobian.  Use the chain rule and \eqref{eq:un:psichimap} to show that
\begin{equation}
\grad_{x,y} \psi_i = \frac{1}{\det J_k} \left<\Delta y_2 \frac{\partial \chi_\ell}{\partial \xi} - \Delta y_1 \frac{\partial \chi_\ell}{\partial \eta}, - \Delta x_2 \frac{\partial \chi_\ell}{\partial \xi} + \Delta x_1 \frac{\partial \chi_\ell}{\partial \eta}\right>. \label{eq:un:gradpsionref}
\end{equation}
Here indices $i$ and $\ell$ have the same relationship as in \eqref{eq:un:psichimap}.  Comparing formula \eqref{eq:of:gradpsionref} for the structured case, what is the underlying reason why \eqref{eq:un:gradpsionref} is a bit more complicated?  % underlying reason is that affine map here includes rotations, while in Chapter \ref{chap:of} it was just translation and axes scaling
\item  \label{exer:un:elementintegranddetails}  Formula \eqref{eq:un:elementintegrand} might require some interpretation before the implementation becomes clear, which is the goal of this Exercise.  Confirm that formulas \eqref{eq:un:trianglemap} and \eqref{eq:un:psichimap} lead to these expansions of expressions in \eqref{eq:un:elementintegrand}:
\begin{align}
a(u^h) &= a(u^h,x(\xi,\eta),y(\xi,\eta)), \label{eq:un:adetails} \\
f(u^h) &= f(u^h,x(\xi,\eta),y(\xi,\eta)), \label{eq:un:fdetails} \\
\psi_i &= \chi_{\ell}(\xi,\eta), \label{eq:un:psichidetails} \\
u^h &= \sum_{j=0}^{N-1} \left\{\begin{matrix} g_D(\bx_j) \\ u_j \end{matrix}\right\} \chi_{\ell'}(\xi,\eta), \label{eq:un:udetails} \\
\grad u^h &= \grad_{x,y} u^h = \sum_{j=0}^{N-1} \left\{\begin{matrix} g_D(\bx_j) \\ u_j \end{matrix}\right\} \grad_{x,y} \psi_j. \label{eq:un:gradudetails}
\end{align}
In \eqref{eq:un:psichidetails} node $\bx_i$ corresponds to vertex $\ell$ on $\triangle_\ast$.  In \eqref{eq:un:udetails} and \eqref{eq:un:gradudetails}, the two cases for computing the coefficient are when $\bx_j \in \partial_D \Omega$ and $\bx_j \notin \partial_D \Omega$, respectively; also node $\bx_j$ corresponds to vertex $\ell'$ on $\triangle_\ast$.  Note that \eqref{eq:un:gradpsionref} allows us to expand $\grad_{x,y} \psi_j$ in \eqref{eq:un:gradudetails}.  Taken together, these expansions make \eqref{eq:un:elementintegrand} implementable.
\item  \label{exer:un:checkquadrature}  The degree of accuracy $n=1,2,3$ of the quadrature rules in Table \ref{tab:un:quadrature} can be checked by comparing the exact integral
\begin{equation}
\iint_{\triangle_\ast} \xi^i \eta^j\,d\xi d\eta = \frac{i!\,j!}{(i+j+2)!}, \label{eq:un:checkquadrature}
\end{equation}
for all cases with $0\le i+j\le n$, against the quadrature result.  Also one should show an inexact quadrature result for some case with $i+j=n+1$.  Write a small program, in the language of your choice, which does so.
\item \label{exer:un:gaussneumann}  In \texttt{unfem.c} we use the midpoint rule, the one-point Gauss rule, for quadrature when computing the Neumann boundary segment contributions $\varphi_\nu^i$; see equation \eqref{eq:un:segmentquadrature}.  Modify \texttt{unfem.c} to optionally use two-point Gaussian quadrature instead.  Only in case 2 will this make any difference.  Show that accuracy noticeably improves for coarse grids, but that this benefit disappears under grid refinement.
% see c/ch7/solns/segmentgauss.c.snippet
\item \label{exer:un:picardconvergence}  In this Exercise let $\|\cdot\|$ denote the $2$-norm: $\|w\| = \sqrt{\bw^\top \bw}$ for $\bw\in\RR^N$.  Assume that the right-hand side of \eqref{eq:un:picardnaive} is bounded, $\|\bb(\bu)\| \le B_b$, and that the nonlinearities are Lipschitz, $\|A(\bu)-A(\bv)\| \le L_A \|\bu-\bv\|$ and $\|\bb(\bu)-\bb(\bv)\| \le L_b \|\bu-\bv\|$.  Assume also that $A(\bu)$ is uniformly positive-definite, so that there is $\delta>0$ for which
    $$\bw^\top A(\bu) \bw \ge \frac{\|\bw\|^2}{\delta}.$$
for all $\bu\in \RR^N$; equivalently this says $\|A^{-1}(\bu)\| \le \delta$.  (This assumption follows, for the FEM matrix in this Chapter, from our assumption of uniform ellipticity of the continuum problem.)  Show that the sequence generated by \eqref{eq:un:picardnaive} is well-defined and bounded, $\|\bu_k\| \le \delta B_b$.  Then show that \eqref{eq:un:picardnaive} is a strict contraction, $\|\bu^{k+1}-\bu^{k}\| \le \alpha \|\bu^{k}-\bu^{k-1}\|$ for some $0\le \alpha < 1$, under the (very strong) assumption that
    $$\alpha = \delta \left(L_A B_b \delta + L_b\right) < 1.$$
It follows from the Banach fixed point theorem that the Picard iteration converges; show this.  These techniques are a great deal more credible and useful when Picard iteration is applied to ODE IVPs \citep{HirschSmaleDevaney2004}; explain why.
\item FIXME compare the results of these two runs, which each solve the (default) linear case 0 problem:
\begin{cline}
$ ./unfem -un_mesh meshes/trap.2 -snes_monitor -ksp_rtol 1.0e-14
$ ./unfem -un_mesh meshes/trap.2 -snes_monitor -ksp_rtol 1.0e-14 -snes_fd
\end{cline}
\item FIXME the result of
\begin{cline}
./unfem -un_mesh meshes/trapneu.1 -un_case 2
\end{cline}
report a numerical error of zero; why?; explains missing marker on coarsest grid in numerical error Figure FIXME
\item FIXME use \texttt{-un\_quaddeg 2,3} on cases 0,1,2 (default is \texttt{-un\_quaddeg 1}); does it make a substantial difference in any cases?; explain why it is noticable for the nonlinear case 1
\item \label{exer:un:allneumannfailure}  We have assumed that the Dirichlet boundary $\partial_D \Omega$ has positive measure (length) so that the linear problem, at least, is known to have a unique solution.  By contrast, confirm experimentally that if $\partial_D\Omega$ is empty then the equations no longer have a unique solution.  This can be done by modifying the case 2 exact solution to use Neumann boundary conditions on the whole of $\partial \Omega$.  A direct solve for the linear equations (\texttt{-ksp\_type preonly -pc\_type lu}) will fail; explain the error message which results.
\item \label{exer:un:allneumannresolution}  Continuing the above Exercise, use \texttt{SNESGetKSP()} and \texttt{KSPSetNullSpace()} to tell the linear solver that the linearization of the Neumann-only problem has constant functions as its null space.  Confirm that direct and iterative solvers now succeed as in the case with non-empty Dirichlet boundary.
\item \label{exer:un:truejacobian} FIXME implement the true Jacobian in the $a=a(x,y)$ case, so that we only add a diagonal $\partial f/\partial u$ term; test on case 1 example and see if improved \pSNES convergence
\item \label{exer:un:bratu} FIXME using result from previous exercise, solve Bratu; compute critical $\lambda$; equals 6.81 according to \pSNES example \texttt{ex5.c}
\item \label{exer:un:robin} FIXME implement Robin boundary condition
\end{enumerate}

