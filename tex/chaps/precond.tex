
When we combine \PETSc \pDMDA and \pSNES objects we get the abilily to do \emph{geometric multigrid} \citep{Briggsetal2000,Trottenbergetal2001} and \emph{domain decomposition} \citep{Smithetal1996,Doleanetal2015} methods.  We will show how these methods act as preconditioners on the linear systems which arise in Newton's method, so this section is about \emph{preconditioned Newton-Krylov} methods.  To get started we introduce the basic ideas of multigrid.

FIXME cite survey \citep{Wathen2015}

\section{Multigrid basics}

FIXME: setup: suppose we are solving 1D Poisson equation on $\RR$, i.e.
    $$- u_{xx} = f(x)$$
with scheme
    $$- \frac{u_{j+1} - 2 u_j + u_{j-1}}{h^2} = f_j,$$
where $f_j = f(x_j)$, or equivalently
    $$- u_{j-1} + 2 u_j - u_{j+1} = h^2 f_j.$$

FIXME: idea (1) in 1D, on unbounded grid with spacing $h$, restriction to every other point takes lowish frequency wave to higher frequency wave on (still unbounded) grid with spacing $2h$

FIXME: idea (2) pointwise iteration version of Poisson FD scheme, e.g.~Jacobi
   $$u_j^{(m+1)} = \frac{1}{2} \left(u_{j-1}^{(m)} + u_{j+1}^{(m)} + h^2 f_j\right) $$
or Gauss-Seidel (where we update in increasing order on $j$)
   $$u_j^{(m+1)} = \frac{1}{2} \left(u_{j-1}^{(m+1)} + u_{j+1}^{(m)} + h^2 f_j\right) $$
will serve as low-pass filter on a given grid

FIXME: idea (3) given $u^{(0)}$ on fine $h$ grid, it is the residual FIXME

FIXME: for more, read \citep{Briggsetal2000} which is at same level as this book


\section{A multigrid-capable Poisson problem code}

The code \texttt{c/ch7/fish2.c} (not shown) solves the same 2D Poisson problem
    $$-\grad^2 u = f,$$
with homogeneous boundary conditions on the square $\Omega=[0,1]\times[0,1]$, as does \texttt{c/ch3/poisson.c} in Chapter \ref{chap:st}.  In fact there is much overlap between the two codes, with similar C functions which set the exact solution, set the \pVec corresponding to $f$, and set up a \pMat $A$ corresponding to the finite-difference discretized operator $-\grad^2$.

This time, however, we adopt the approach common to the second half of this book, which is to say we set up a \PETSc \pSNES object.  It does Newton's method, even though the problem is linear.  In \texttt{c/ch7/fish2.c} there is a residual-evaluation function, corresponding to the discretized form of the PDE; heuristically it computes $\bF(\bu) = -\grad^2 u - f$.  The Jacobian of this residual function gives precisely the same matrix as was constructed by \texttt{c/ch3/poisson.c}.

The two codes compute the same solution as long as we tighten the Krylov solver tolerance:\sidenote{Without this tightening \texttt{fish2.c} computes the more accurate solution because the \pSNES asks for iteration so as to ``clean up'' the small residual; note the default tolerances for \texttt{-snes\_rtol} of $10^{-8}$ and for \texttt{-ksp\_rtol} of $10^{-5}$.}
\begin{cline}
$ cd c/ch7/
$ make fish2
...
$ ./fish2 -ksp_rtol 1.0e-10
on 9 x 9 grid:  error |u-uexact|_inf = 0.000763883
$ cd ../ch3/
$ make poisson
...
$ ./poisson -ksp_rtol 1.0e-10
on 9 x 9 grid:  error |u-uexact|_inf = 0.000763883
\end{cline}

FIXME

\section{Grid sequencing on a nonlinear problem}

FIXME

\section{Domain decomposition preconditioners}

FIXME

% question by Gideon Simpson:
% ...
%> Nope, I'm not doing any grid sequencing. Clearly that makes a lot of
%> sense, to solve on a spatially coarse mesh for the field variables,
%> interpolate onto the finer mesh, and then solve again.  I'm not entirely
%> clear on the practical implementation
%
% SNES should do this automatically using -snes_grid_sequence <k>.  If this
% does not work, complain. Loudly.
%   Matt
% ... later in correspondence ...
%> 4.  When I do SNESSolve(snes, NULL, U) with grid sequencing, U is not
%> the solution on the fine mesh.  But what is it?  Is it still the starting
%> guess, or is it the solution on the coarse mesh?
%
% It will contain the solution on the coarse mesh. After SNESSolve() call
% SNESGetSolution() and it will give back the solution on the fine mesh.
%  Barry

\section{Composing preconditioners}

FIXME:  block Jacobi and GS/SOR?

FIXME: somewhere describe Nachtigal et al 1992 result that KSP are strictly inequivalent

\begin{comment}
> Hi all,
>
> Is weighted Jacobi available as a preconditioner ? I can't find it in the
> list of preconditioners. If not, what is the rationale between this choice
> ? It is pretty straightforward to code, so if it is not available I can do
> it without problem I guess, but I am just wondering. In the matrix-free
> case where SOR is not available by default, it may be better than pure
> Jacobi, and much easier to parallelize than SOR.
>
>   Timothee Nicolas

I believe what you are looking for is defined by the following options
  -ksp_type richardson
  -ksp_richardson_scale <value>
  -pc_type jacobi

Thanks,
  Dave May
\end{comment}

\begin{comment}
DAVE MAY petsc-users 2/9/2016:
...
To be sure your code is working correctly, test it using a preconditioner
which isn't dependent on the partitioning of the matrix. I would use these
options:
  -pc_type jacobi
  -ksp_monitor_true_residual

The last option is useful as it will report both the preconditioned
residual and the true residual. If the operator is singular, or close to
singular, gmres-ILU or gmres-BJacobi-ILU can report a preconditioned
residual which is small, but is orders of magnitude different from the true
residual.

Thanks,
  Dave
\end{comment}

%EXERCISE: make fish2.c more efficient by NOT doing "divide by hx^2 then mult by vol"  and instead "mult by hy*hz/hx"; measure performance difference; note this is already done by fish3.c
