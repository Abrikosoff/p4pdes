#!/usr/bin/env python

# the data is generated by a one-time-step -ice_verif 2 run (Halfar):
# $ for LEV in 4 5 6 7 8 9 10; do timer ./ice -ice_verif 2 -ts_type beuler -ice_tf 10.0 -ice_dtinit 10.0 -da_refine $LEV -pc_type gamg -snes_converged_reason -ksp_converged_reason; done | tee gamgstudy.txt

# note the -da_refine 10 run fills 10 Gb memory

# FIXME extend to ILU, MG

# when you look at the -log_view you see almost all the time is in evaluation of
# IFunction()/RHSFunction(), i.e. SNESFunctionEval; this is true with -snes_fd_color
# but it would still be true with an analytical Jacobian

# thus set-up cost of GAMG not very concerning for now

# we see the success of GAMG as the number of Krylov iterations is nearly
# constant as the degrees of freedom go from 48^2 = 2x10^3 to 3072^2 = 9x10^6

# the issue, as much as any other, is seen in the increase in Newton iterations
# I think this is from the moving free boundary

# FIXME: calculate how many grid spaces the free boundary moves in this Halfar solution in this time interval

import numpy as np
import matplotlib.pyplot as plt

# mx, kspsum, snes, time
data = np.array([  [48, 9, 3, 0.22],
                   [96, 10, 3, 0.69],
                   [192, 11, 3, 3.54],
                   [384, 15, 4, 14.71],
                   [768, 21, 5, 64.08],
                   [1536, 37, 9, 458.41],
                   [3072, 57, 14, 3040.50] ])

# m = mx^2  is number of degrees of freedom
mx = data[:,0]
m = mx * mx
snes = data[:,2]
kspsum = data[:,1]
time = data[:,3]

plt.loglog(m,kspsum / snes,'o',ms=14,label='KSP iterations per Newton')
plt.loglog(m,snes,'*',ms=16,label='Newton iterations')
plt.loglog(m,1.0e3 * time / m,'s',ms=14,label='time (ms) per degree of freedom')

plt.grid('on')
plt.xlabel('degrees of freedom')
plt.legend(fontsize=12)

plt.show()

